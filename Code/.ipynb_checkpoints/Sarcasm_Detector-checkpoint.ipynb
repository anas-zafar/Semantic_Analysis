{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm Detector\n",
    "___\n",
    "1. [Importing python modules.](#Importing)\n",
    "2. [Setting up the DataSet Directory path.](#Dataset)\n",
    "3. [Loading the dataset.](#LoadingDataset)\n",
    "    - 3.1 Showing snapshot of dataset, `df.head()`.\n",
    "    - 3.2 Removing the unwanted columns.\n",
    "    - 3.3 Pie Chart of sarcastic and non sarcastic examples in the dataset.\n",
    "    \n",
    "    \n",
    "4. [Data Preprocessing](#preprocessing)\n",
    "    - 4.1 Lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Importing\"></a>\n",
    "\n",
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Import\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn import metrics, svm\n",
    "\n",
    "from senticnet.senticnet import SenticNet\n",
    "from sentistrength import PySentiStr\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from FeatureCount import SequencePunctuationCount ,\\\n",
    "                         SequenceCharacterCount , \\\n",
    "                         CapitalizedCount , \\\n",
    "                         ExclamationCount , \\\n",
    "                         EmojiCount \n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "print('Successfully Import')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Dataset\"></a>\n",
    "### 2. Dataset and Base directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(\"\"))\n",
    "\n",
    "DATASET_PATH = os.path.join(DIR_PATH, \"DataSet\")\n",
    "\n",
    "DATASET_SARCASM_HEDDLINES_V1= os.path.join(DATASET_PATH, \"Sarcasm_Headlines_Dataset_v1.json\")\n",
    "DATASET_SARCASM_HEDDLINES_V2= os.path.join(DATASET_PATH, \"Sarcasm_Headlines_Dataset_v2.json\")\n",
    "\n",
    "DATASET_REDDIT_TEST = os.path.join(DATASET_PATH, \"reddit_test.csv\")\n",
    "DATASET_SARCASTIC = os.path.join(DATASET_PATH, \"sarcastic.json\")\n",
    "\n",
    "CODE_PATH = os.path.join(DIR_PATH, \"Code\")\n",
    "PICKLES_PATH = os.path.join(DIR_PATH, \"Pickles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "infile  = open(os.path.join(DATASET_PATH, \"sarcastic.txt\"), \"r\")\n",
    "outfile = open(DATASET_SARCASTIC, \"w\") \n",
    "for heading in infile:\n",
    "    heading = heading.replace(\"\\n\", \"\")\n",
    "    json_object = json.dumps({'headline':heading,'is_sarcastic':1}) \n",
    "    outfile.write(json_object) \n",
    "    outfile.write('\\n') \n",
    "outfile.close()\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"LoadingDataset\"></a>\n",
    "### 3. Loading dataset into pandas frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Light travels faster than sound. This is why s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When people ask me stupid questions, it is my ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's okay if you don't like me. Not everyone h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You look good when your eyes are closed, but y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mirrors can't talk, lucky for you they can't l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  Light travels faster than sound. This is why s...             1\n",
       "1  When people ask me stupid questions, it is my ...             1\n",
       "2  It's okay if you don't like me. Not everyone h...             1\n",
       "3  You look good when your eyes are closed, but y...             1\n",
       "4  Mirrors can't talk, lucky for you they can't l...             1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsh1 = pd.read_json(DATASET_SARCASM_HEDDLINES_V1, lines=True)\n",
    "dsh1.head()\n",
    "\n",
    "dsh2 = pd.read_json(DATASET_SARCASM_HEDDLINES_V2, lines=True)\n",
    "dsh2.head()\n",
    "\n",
    "ds = pd.read_json(DATASET_SARCASTIC,lines=True)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Removing unwanted columns , merge and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hardened snacker keeps trying to rediscover th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scientists announce today best time to look di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lee daniels made 'star' for 'white people to f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harvey weinstein and the danger of performativ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bush dies peacefully in his sleep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  hardened snacker keeps trying to rediscover th...             1\n",
       "1  scientists announce today best time to look di...             1\n",
       "2  lee daniels made 'star' for 'white people to f...             0\n",
       "3  harvey weinstein and the danger of performativ...             0\n",
       "4                  bush dies peacefully in his sleep             1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT  = 'headline'\n",
    "LABEL = 'is_sarcastic'\n",
    "dsh1   = dsh1[[TEXT, LABEL]]\n",
    "dsh2   = dsh2[[TEXT, LABEL]]\n",
    "\n",
    "df = pd.concat([dsh1,dsh2,ds])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Pie Chart of 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"Sarcastic\", \"Not Sarcastic\"]\n",
    "# Number or 1's, Number of 0's\n",
    "sizes = [df.groupby(['is_sarcastic']).count().values[1][0], df.groupby(['is_sarcastic']).count().values[0][0]]\n",
    "fig1, ax1 = plt.subplots(figsize=(7, 7))\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.3f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"preprocessing\"></a>\n",
    "### 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Lemmatization and removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# Replacing double quotes with single, within a string\n",
    "df[TEXT] = df[TEXT].apply(lambda x: x.replace(\"\\\"\", \"\\'\"))\n",
    "# Removing unnecessary special characters, keeping only , . ! ? '\n",
    "df[TEXT] = df[TEXT].apply(lambda x: re.sub(r\"[^!?.,a-zA-Z0-9\\' ]+\", '', x))\n",
    "# Lemmatization on verbs\n",
    "df[TEXT] = df[TEXT].apply(lambda sentence : ' '.join([wordnet_lemmatizer.lemmatize(word, pos='v') for word in word_tokenize(sentence)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drt = pd.read_csv(DATASET_REDDIT_TRAINING)\n",
    "# drt.rename(columns = {'body':'headline','sarcasm_tag':'is_sarcastic'},inplace=True)\n",
    "# drt['is_sarcastic'] = (drt['is_sarcastic']=='yes').astype(int)\n",
    "\n",
    "# drt.head()\n",
    "\n",
    "# sn = SenticNet()\n",
    "# senti = PySentiStr()\n",
    "# senti.setSentiStrengthPath(CODE_PATH + '/sentistrength/SentiStrength.jar')\n",
    "# senti.setSentiStrengthLanguageFolderPath(CODE_PATH +'/sentistrength/SentStrength_Data/')\n",
    "\n",
    "# sentiment_score = []\n",
    "# for sentences in df[TEXT]:\n",
    "#     temp = []\n",
    "#     for sentence in sent_tokenize(sentences):\n",
    "#         senti_pos , senti_neg = senti.getSentiment(sentence,score='dual')[0]\n",
    "#         senti_pos -= 1\n",
    "#         if senti_neg == -1: \n",
    "#             senti_neg = 0\n",
    "#         sum_pos_score = 0\n",
    "#         sum_neg_score = 0\n",
    "#         for word in word_tokenize(sentence):\n",
    "#             try:\n",
    "#                 w_score = float(sn.polarity_intense(word))*5\n",
    "#             except KeyError:\n",
    "#                 w_score = 0\n",
    "#             if w_score > 0:\n",
    "#                 sum_pos_score = sum_pos_score + w_score\n",
    "#             elif w_score < 0:\n",
    "#                 sum_neg_score = sum_neg_score + w_score\n",
    "#         sum_pos_score = (sum_pos_score+senti_pos)/2\n",
    "#         sum_neg_score = (sum_neg_score+senti_neg)/2\n",
    "#         temp.append((sum_pos_score , sum_neg_score))\n",
    "#     sentiment_score.append(temp)\n",
    "# dbfile = open(os.path.join(PICKLES_PATH, \"sentiment_score\"), 'wb') \n",
    "# pickle.dump(sentiment_score, dbfile)                      \n",
    "# dbfile.close() \n",
    "# dbfile          = open(os.path.join(PICKLES_PATH, \"sentiment_score\"), 'rb') \n",
    "# sentiment_score = pickle.load(dbfile)\n",
    "# additional_features = [] \n",
    "# for sentence_score in sentiment_score:\n",
    "#     contra     = []\n",
    "#     pos_low    = []\n",
    "#     pos_medium = []\n",
    "#     pos_high   = []\n",
    "#     neg_low    = []\n",
    "#     neg_medium = []\n",
    "#     neg_high   = []\n",
    "#     for sum_pos_score,sum_neg_score in sentence_score:\n",
    "#         contra.append(int(sum_pos_score > 0 and abs(sum_neg_score) > 0))\n",
    "#         pos_low.append(int(sum_pos_score < 0))\n",
    "#         pos_medium.append(int(sum_pos_score >= 0 and sum_pos_score <= 1))\n",
    "#         pos_high.append(int(sum_pos_score >= 2))\n",
    "#         neg_low.append(int(sum_neg_score < 0))\n",
    "#         neg_medium.append(int(sum_neg_score >= 0 and sum_neg_score <= 1))\n",
    "#         neg_high.append(int(sum_neg_score >= 2))\n",
    "#     additional_features.append([max(contra),max(pos_low),max(pos_medium),max(pos_high),max(neg_low),max(neg_medium),max(neg_high)])\n",
    "# dbfile.close()    \n",
    "# i = -1;\n",
    "# for tweet in df[TEXT]:\n",
    "#     i = i + 1\n",
    "#     punctuation_count = SequencePunctuationCount(tweet)\n",
    "#     character_count   = SequenceCharacterCount(tweet)\n",
    "#     capitalized_count = CapitalizedCount(tweet)\n",
    "#     exclamation_count = ExclamationCount(tweet)\n",
    "#     emoji_count       = EmojiCount(tweet)\n",
    "#     f_count           = [punctuation_count,character_count,capitalized_count,exclamation_count,emoji_count] \n",
    "#     for count in f_count:\n",
    "#         f_low    = int(count == 0 )\n",
    "#         f_medium = int(count >= 1 and count <= 3 )\n",
    "#         f_high   = int(count >= 4)\n",
    "#         additional_features[i].append(f_low)\n",
    "#         additional_features[i].append(f_medium)\n",
    "#         additional_features[i].append(f_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"svm\"></a>\n",
    "### 5. Implementing SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Add addtional feature and Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[TEXT].to_list()\n",
    "Y = df[LABEL].to_list()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "out_file = open(os.path.join(PICKLES_PATH, \"vocab.pickle\"), \"wb\")\n",
    "pickle.dump(vectorizer.vocabulary_, out_file)\n",
    "out_file.close()\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24101) 55416\n",
      "(44332, 24101) 44332\n",
      "(11084, 24101) 11084\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, len(Y))\n",
    "print(X_train.shape, len(Y_train))\n",
    "print(X_test.shape, len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.903915553951642\n",
      "Train Accuracy: 0.9484368656110435\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "test_accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
    "Y_pred = model.predict(X_train)\n",
    "train_accuracy = metrics.accuracy_score(Y_train, Y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7335579683015101\n",
      "Train Accuracy: 0.9999465126230209\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='poly')\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "test_accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
    "Y_pred = model.predict(X_train)\n",
    "train_accuracy = metrics.accuracy_score(Y_train, Y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='rbf')\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "test_accuracy  = metrics.accuracy_score(Y_test, Y_pred)\n",
    "Y_pred = model.predict(X_train)\n",
    "train_accuracy = metrics.accuracy_score(Y_train, Y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8717069649945868\n",
      "Train Accuracy: 0.8965579464970451\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='sigmoid')\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "test_accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
    "Y_pred = model.predict(X_train)\n",
    "train_accuracy = metrics.accuracy_score(Y_train, Y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC()\n",
      "Test Accuracy: 0.9242150848069289\n",
      "Train Accuracy: 0.9783677704592619\n"
     ]
    }
   ],
   "source": [
    "model = svm.LinearSVC()\n",
    "print(model)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "test_accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
    "Y_pred = model.predict(X_train)\n",
    "train_accuracy = metrics.accuracy_score(Y_train, Y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "out_file = open(os.path.join(PICKLES_PATH, \"model.pickle\"), \"wb\")\n",
    "pickle.dump(model, out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB()\n",
      "Test Accuracy: 0.8836160230963551\n",
      "Train Accuracy: 0.9287873319498331\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "test_accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
    "Y_pred = model.predict(X_train)\n",
    "train_accuracy = metrics.accuracy_score(Y_train, Y_pred)\n",
    "print(model)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, svm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "DIR_PATH = os.path.dirname(os.path.abspath(\"\"))\n",
    "PICKLES_PATH = os.path.join(DIR_PATH, \"Pickles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sentence : hell !!!!!!!!!!!\n",
      "\u001b[1mSentence : \u001b[0m hell ! ! ! ! ! ! ! ! ! ! !\n",
      "\u001b[1mSarcastic features : \u001b[0m [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 0]\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n"
     ]
    }
   ],
   "source": [
    "sentence = input('Enter sentence : ')\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# # Replacing double quotes with single, within a string\n",
    "sentence = sentence.replace(\"\\\"\", \"\\'\")\n",
    "# # Removing unnecessary special characters, keeping only ,  ! ? \n",
    "sentence = re.sub(r\"[^!?,a-zA-Z0-9\\ ]+\", '', sentence)\n",
    "# # Lemmatization on verbs\n",
    "sentence = ' '.join([wordnet_lemmatizer.lemmatize(word, pos='v') for word in word_tokenize(sentence)])\n",
    "\n",
    "sn = SenticNet()\n",
    "senti = PySentiStr()\n",
    "senti.setSentiStrengthPath(CODE_PATH + '/sentistrength/SentiStrength.jar')\n",
    "senti.setSentiStrengthLanguageFolderPath(CODE_PATH +'/sentistrength/SentStrength_Data/')\n",
    "\n",
    "sentiment_score = []\n",
    "\n",
    "for sen in sent_tokenize(sentence):\n",
    "    senti_pos , senti_neg = senti.getSentiment(sen,score='dual')[0]\n",
    "    senti_pos -= 1\n",
    "    if senti_neg == -1: \n",
    "        senti_neg = 0\n",
    "    sum_pos_score = 0\n",
    "    sum_neg_score = 0\n",
    "    for word in word_tokenize(sen):\n",
    "        try:\n",
    "            w_score = float(sn.polarity_intense(word))*5\n",
    "        except KeyError:\n",
    "            w_score = 0\n",
    "        if w_score > 0:\n",
    "            sum_pos_score = sum_pos_score + w_score\n",
    "        elif w_score < 0:\n",
    "            sum_neg_score = sum_neg_score + w_score\n",
    "    sum_pos_score = (sum_pos_score+senti_pos)/2\n",
    "    sum_neg_score = (sum_neg_score+senti_neg)/2\n",
    "    sentiment_score.append((sum_pos_score , sum_neg_score))\n",
    "additional_features_s  = [] \n",
    "additional_features_ns = [] \n",
    "\n",
    "contra     = []\n",
    "pos_low    = []\n",
    "pos_medium = []\n",
    "pos_high   = []\n",
    "neg_low    = []\n",
    "neg_medium = []\n",
    "neg_high   = []\n",
    "\n",
    "for sum_pos_score,sum_neg_score in sentiment_score:\n",
    "    contra.append(int(sum_pos_score > 0 and abs(sum_neg_score) > 0))\n",
    "    pos_low.append(int(sum_pos_score < 0))\n",
    "    pos_medium.append(int(sum_pos_score >= 0 and sum_pos_score <= 1))\n",
    "    pos_high.append(int(sum_pos_score >= 2))\n",
    "    neg_low.append(int(sum_neg_score < 0))\n",
    "    neg_medium.append(int(sum_neg_score >= 0 and sum_neg_score <= 1))\n",
    "    neg_high.append(int(sum_neg_score >= 2))\n",
    "additional_features_s = additional_features_s + [max(pos_medium),max(pos_high),max(neg_medium),max(neg_high)]\n",
    "additional_features_ns = additional_features_ns + [max(pos_low),max(neg_low)]\n",
    "\n",
    "tweet             = sentence\n",
    "punctuation_count = SequencePunctuationCount(tweet)\n",
    "character_count   = SequenceCharacterCount(tweet)\n",
    "capitalized_count = CapitalizedCount(tweet)\n",
    "exclamation_count = ExclamationCount(tweet)\n",
    "#     emoji_count       = EmojiCount(tweet)\n",
    "f_count           = [punctuation_count,character_count,capitalized_count,exclamation_count] \n",
    "for count in f_count:\n",
    "    f_low    = int(count == 0 )\n",
    "    f_medium = int(count >= 1 and count <= 3 )\n",
    "    f_high   = int(count >= 4)\n",
    "    additional_features_s = additional_features_s + [f_medium,f_high]\n",
    "    additional_features_ns = additional_features_ns + [f_low]\n",
    "X = [sentence]\n",
    "\n",
    "in_file = open(os.path.join(PICKLES_PATH, \"vocab.pickle\"), \"rb\")\n",
    "vocab = pickle.load(in_file)\n",
    "in_file.close()\n",
    "\n",
    "in_file = open(os.path.join(PICKLES_PATH, \"model.pickle\"), \"rb\")\n",
    "model = pickle.load(in_file)\n",
    "in_file.close()\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary=vocab)\n",
    "X = vectorizer.fit_transform(X)\n",
    "ans = int(sum(model.predict(X)))\n",
    "\n",
    "print('\\033[1mSentence : \\033[0m',sentence)\n",
    "print('\\033[1mSarcastic features : \\033[0m',additional_features_s)\n",
    "print('\\033[1mNot Sarcastic features : \\033[0m',additional_features_ns)\n",
    "print('\\033[1mContradict : \\033[0m',max(contra))\n",
    "print('\\033[1mModel Predict : \\033[0m',ans)\n",
    "print('\\033[1mMy obs : \\033[0m',int((sum(additional_features_s)  >= sum(additional_features_ns)) and max(contra) == 1))\n",
    "print('\\033[1mFinal Prd : \\033[0m',end='')\n",
    "\n",
    "if ans == 1 or int((sum(additional_features_s)  >= sum(additional_features_ns)) and max(contra) == 1):\n",
    "    print('Sarcastic')\n",
    "else:\n",
    "    print('Not Sarcastic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSentence : \u001b[0m harden snacker keep try to rediscover that first mindblowing nacho cheese high\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m scientists announce today best time to look directly at sun\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m lee daniels make 'star ' for 'white people to feel good about be white '\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m harvey weinstein and the danger of performative 'wokeness '\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m bush die peacefully in his sleep\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m 'mean girls ' director sign on for new comedy\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m trump 's budget nominee still think social security be a ponzi scheme\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m brexit a cousin of trumpism ? a distant cousin of fascism ?\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m donald trump play a dangerous game of telephone\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m white castle plunder by turks\n",
      "\u001b[1mSarcastic features : \u001b[0m [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m 911 call from parkland shoot reveal terror of parent desperate for answer\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m eat entire box of donuts not originally part of even 's plan\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m new college freshman refer to dorm by actual name\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m gina rodriguez be give trailblazing women the award show they deserve\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m apparently reese witherspoon like j.crew as much as we do\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m child plead case for why family rabbit should be name aunt susan\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m a multiethnic easter\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m hopeless resignation receive massive postdebate bump\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m panic oyster pray that lump it feel form only a pearl\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m few years in military would have really straighten out trouble teen kill on first tour of afghanistan\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m over 300 women chime in after l.a. time detail director 's sex abuse reputation\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 0, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSentence : \u001b[0m new airport security rule could mean 'short interview ' with passengers\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m make a live ... and a love\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 0, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m marcellus williams prosecutor draw scrutiny in ferguson police shoot\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m area secretary lotions obsessively\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m pope beatify god in important step toward sainthood\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m russians mint 'in trump we trust ' coin ahead of u.s. inauguration\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 0, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m 5 step to get you from shy to sociable\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m earthquake kill 54 rescue workers ' weekend plan\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m allstate charge with operate protection racket\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m man unknowingly purchase lifetime supply of condoms\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m excollege basketball star wait 2 years to send the perfect tweet\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m u.s. cities be n't ready to fend off the next flint\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 0, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m open letter to all potential mayoral candidates a response would be nice\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m the twoforone move that tone abs and arm at the same time\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m walnuts improve area chicken salad\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m spring on spring street a tale of rebirth\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m break up with god\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m area man a staunch singlegender voter\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m zoo orangutan feel he really connect with iowa woman\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m kinky lawn chair like leave woman with mark all over her legs\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m russian roulette taxpayers could be on the hook for trillions in oil derivatives\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m secondgrader like to save purple pills for last\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSentence : \u001b[0m beautiful spring day no match for last 35 years of man 's life\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m be there a villain in the 2014 election ?\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m man charge in disappearance of north carolina toddler\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m uber charge passenger over 14,000 for 5mile ride across toronto\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m no , bruce jenner be not have a 'midlife crisis '\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 0\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m nation admit it probably go to come out of this have learn completely wrong lessons\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 1, 1, 0, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 1\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "\u001b[1mSentence : \u001b[0m usa original movie not that original\n",
      "\u001b[1mSarcastic features : \u001b[0m [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\u001b[1mNot Sarcastic features : \u001b[0m [0, 0, 1, 1, 1, 1]\n",
      "\u001b[1mActual : \u001b[0m 1\n",
      "\u001b[1mContradict : \u001b[0m 0\n",
      "\u001b[1mModel Predict : \u001b[0m 0\n",
      "\u001b[1mMy obs : \u001b[0m 0\n",
      "\u001b[1mFinal Prd : \u001b[0mNot Sarcastic\n",
      "-----------------------------------------------------------------------\n",
      "50\n",
      "54.0\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "i = 0\n",
    "for sentence in df[TEXT]:\n",
    "    if i == 50:\n",
    "        break\n",
    "    sentiment_score = []\n",
    "    for sen in sent_tokenize(sentence):\n",
    "        senti_pos , senti_neg = senti.getSentiment(sen,score='dual')[0]\n",
    "        senti_pos -= 1\n",
    "        if senti_neg == -1: \n",
    "            senti_neg = 0\n",
    "        sum_pos_score = 0\n",
    "        sum_neg_score = 0\n",
    "        for word in word_tokenize(sen):\n",
    "            try:\n",
    "                w_score = float(sn.polarity_intense(word))*5\n",
    "            except KeyError:\n",
    "                w_score = 0\n",
    "            if w_score > 0:\n",
    "                sum_pos_score = sum_pos_score + w_score\n",
    "            elif w_score < 0:\n",
    "                sum_neg_score = sum_neg_score + w_score\n",
    "        sum_pos_score = (sum_pos_score+senti_pos)/2\n",
    "        sum_neg_score = (sum_neg_score+senti_neg)/2\n",
    "        sentiment_score.append((sum_pos_score , sum_neg_score))\n",
    "    additional_features_s  = [] \n",
    "    additional_features_ns = [] \n",
    "    \n",
    "    contra     = []\n",
    "    pos_low    = []\n",
    "    pos_medium = []\n",
    "    pos_high   = []\n",
    "    neg_low    = []\n",
    "    neg_medium = []\n",
    "    neg_high   = []\n",
    "\n",
    "    for sum_pos_score,sum_neg_score in sentiment_score:\n",
    "        contra.append(int(sum_pos_score > 0 and abs(sum_neg_score) > 0))\n",
    "        pos_low.append(int(sum_pos_score < 0))\n",
    "        pos_medium.append(int(sum_pos_score >= 0 and sum_pos_score <= 1))\n",
    "        pos_high.append(int(sum_pos_score >= 2))\n",
    "        neg_low.append(int(sum_neg_score < 0))\n",
    "        neg_medium.append(int(sum_neg_score >= 0 and sum_neg_score <= 1))\n",
    "        neg_high.append(int(sum_neg_score >= 2))\n",
    "    additional_features_s = additional_features_s + [max(pos_medium),max(pos_high),max(neg_medium),max(neg_high)]\n",
    "    additional_features_ns = additional_features_ns + [max(pos_low),max(neg_low)]\n",
    "    \n",
    "    tweet             = sentence\n",
    "    punctuation_count = SequencePunctuationCount(tweet)\n",
    "    character_count   = SequenceCharacterCount(tweet)\n",
    "    capitalized_count = CapitalizedCount(tweet)\n",
    "    exclamation_count = ExclamationCount(tweet)\n",
    "#   emoji_count       = EmojiCount(tweet)\n",
    "    f_count           = [punctuation_count,character_count,capitalized_count,exclamation_count] \n",
    "    for count in f_count:\n",
    "        f_low    = int(count == 0 )\n",
    "        f_medium = int(count >= 1 and count <= 3 )\n",
    "        f_high   = int(count >= 4)\n",
    "        additional_features_s = additional_features_s + [f_medium,f_high]\n",
    "        additional_features_ns = additional_features_ns + [f_low]\n",
    "    print('\\033[1mSentence : \\033[0m',sentence)\n",
    "    print('\\033[1mSarcastic features : \\033[0m',additional_features_s)\n",
    "    print('\\033[1mNot Sarcastic features : \\033[0m',additional_features_ns)\n",
    "    print('\\033[1mActual : \\033[0m',df[LABEL][i])\n",
    "    print('\\033[1mContradict : \\033[0m',max(contra))\n",
    "    print('\\033[1mModel Predict : \\033[0m',ans)\n",
    "    print('\\033[1mMy obs : \\033[0m',int((sum(additional_features_s)  >= sum(additional_features_ns)) and max(contra) == 1))\n",
    "    print('\\033[1mFinal Prd : \\033[0m',end='')\n",
    "\n",
    "    if int((sum(additional_features_s)  >= sum(additional_features_ns)) and max(contra) == 1) == df[LABEL][i]:\n",
    "        cnt = cnt + 1\n",
    "    if int((sum(additional_features_s)  >= sum(additional_features_ns)) and max(contra) == 1):\n",
    "        print('Sarcastic')\n",
    "    else:\n",
    "        print('Not Sarcastic')\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    i = i + 1\n",
    "print((cnt/i)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
